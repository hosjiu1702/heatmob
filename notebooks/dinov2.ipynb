{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065e80a2-225b-493c-a820-ab2a51404962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "# last_hidden_states = outputs[0]\n",
    "\n",
    "# # We have to force return_dict=False for tracing\n",
    "# model.config.return_dict = False\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     traced_model = torch.jit.trace(model, [inputs.pixel_values])\n",
    "#     traced_outputs = traced_model(inputs.pixel_values)\n",
    "\n",
    "# print((last_hidden_states - traced_outputs[0]).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c493ed-fdf7-43e8-a63b-b975c902ba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f15a5366-8e83-4a7f-af03-8a4a920d5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(outputs.last_hidden_state, outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd1b0822-a2b5-4897-a686-bb38ab55cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_lhs = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c0bc1a4-d446-4998-baf4-8d0d5ff7e650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(tmp_lhs, outputs.hidden_states[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbcb72fd-b044-4dcd-81d3-52a4b1922830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(outputs.hidden_states[-9], outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5353da6-d00f-4f93-b99c-949048c42c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1747, -0.4729,  1.0936,  ...,  0.2041,  1.1101,  0.1363],\n",
       "         [-3.2780, -0.8269, -0.9210,  ...,  1.4415, -0.5364, -0.8757],\n",
       "         [-2.9129,  1.1284, -0.7306,  ...,  0.6959, -1.8791, -2.3638],\n",
       "         ...,\n",
       "         [-0.5463,  1.4382, -0.2564,  ...,  0.1874, -2.9950,  0.4068],\n",
       "         [-3.0848,  2.0568,  1.5137,  ...,  0.9157, -2.7059,  2.2017],\n",
       "         [-0.7499,  0.0902,  1.3731,  ..., -0.2961, -2.3682, -0.1329]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36295c32-7967-413c-af0f-caff2879b481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4676, -0.2195,  0.3422,  ...,  0.6307,  0.4981, -0.4416],\n",
       "         [-1.7904,  0.1015, -0.0225,  ...,  2.2653, -0.1758, -0.6733],\n",
       "         [-3.2630,  1.2945, -0.8190,  ...,  1.6167, -2.8213, -3.6856],\n",
       "         ...,\n",
       "         [-0.4991,  1.5252, -0.2410,  ...,  1.0018, -3.3789, -0.2315],\n",
       "         [-3.0342,  2.1589,  0.8684,  ...,  1.8011, -3.3787,  1.5811],\n",
       "         [-0.8713,  0.3466,  0.9158,  ...,  0.5766, -3.3744, -0.9730]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b8ca380-b140-4779-b146-4af894660a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dinov2Model(\n",
       "  (embeddings): Dinov2Embeddings(\n",
       "    (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): Dinov2Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x Dinov2Layer(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attention): Dinov2Attention(\n",
       "          (attention): Dinov2SelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): Dinov2SelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layer_scale1): Dinov2LayerScale()\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Dinov2MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_scale2): Dinov2LayerScale()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef432eb5-56fa-4d9f-b80c-8e725fdcd6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21862de1-a8e7-4d9f-b4a5-e71fa993d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 257, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c2698a-7eac-496e-a95f-4d8ef666d804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.dinov2.modeling_dinov2.Dinov2Model"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e284f4-d83e-406a-8968-36454068427b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c11831e2-593a-4770-a934-88da93f2b225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 257, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev venv",
   "language": "python",
   "name": "dev-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
